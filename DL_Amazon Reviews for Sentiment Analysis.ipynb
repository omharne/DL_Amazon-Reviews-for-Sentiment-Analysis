{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iioo7Q7AwhYI"
      },
      "source": [
        " ## Project  : Amazon reviews analysis. This dataset consists of a few million Amazon customer reviews (input text) and star ratings (output labels) for learning how to train fastText for sentiment analysis.\n",
        "dataset link:-  \"https://www.kaggle.com/datasets/bittlingmayer/amazonreviews\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCYKMaU2waQp",
        "outputId": "6a48921a-b64e-4a95-8a62-b04780a7b72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2lL0ZSRwjPr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF4c8w-JwaNk"
      },
      "outputs": [],
      "source": [
        "def get_labels_and_texts(file):\n",
        "    labels = []\n",
        "    texts = []\n",
        "    for line in bz2.BZ2File(file):\n",
        "        x = line.decode(\"utf-8\")\n",
        "        labels.append(int(x[9]) - 1)\n",
        "        texts.append(x[10:].strip())\n",
        "    labels = labels[:int(len(labels)*0.01)]\n",
        "    texts = texts[:int(len(texts)*0.01)]\n",
        "    return np.array(labels), texts\n",
        "train_labels, train_texts = get_labels_and_texts('/content/drive/MyDrive/Colab Notebooks/DL assing 1N 2/train.ft.txt.bz2')\n",
        "test_labels, test_texts = get_labels_and_texts('/content/drive/MyDrive/Colab Notebooks/DL assing 1N 2/test.ft.txt.bz2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEVSBFbZwaK8",
        "outputId": "500f389c-c0cf-4591-9761-4a6ee6e2d5fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  label\n",
            "0  Stuning even for the non-gamer: This sound tra...      1\n",
            "1  The best soundtrack ever to anything.: I'm rea...      1\n",
            "2  Amazing!: This soundtrack is my favorite music...      1\n",
            "3  Excellent Soundtrack: I truly like this soundt...      1\n",
            "4  Remember, Pull Your Jaw Off The Floor After He...      1\n",
            "                                                text  label\n",
            "0  Great CD: My lovely Pat has one of the GREAT v...      1\n",
            "1  One of the best game music soundtracks - for a...      1\n",
            "2  Batteries died within a year ...: I bought thi...      0\n",
            "3  works fine, but Maha Energy is better: Check o...      1\n",
            "4  Great for the non-audiophile: Reviewed quite a...      1\n"
          ]
        }
      ],
      "source": [
        "train_df=pd.DataFrame(zip(train_texts,train_labels),columns=['text','label'])\n",
        "print(train_df.head())\n",
        "test_df=pd.DataFrame(zip(test_texts,test_labels),columns=['text','label'])\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UApDyg-D0W9l"
      },
      "outputs": [],
      "source": [
        "def remove_special_characters(text):\n",
        "  text=text.str.lower()\n",
        "  text=text.apply(lambda x: re.sub(r'[0-9]+','',x))\n",
        "  text=text.apply(lambda x: re.sub(r'@mention',' ',x))\n",
        "  text=text.apply(lambda x: re.sub(r'https?:\\/\\/\\S+', ' ',x))\n",
        "  text=text.apply(lambda x: re.sub(r\"www.\\[a-z]?\\.?(com)+|[a-z]+\\.(com)\", ' ',x))\n",
        "  text=text.apply(lambda x: re.sub(r\"[_\\,\\>\\(\\-:\\)\\\\\\/\\!\\.\\^\\!\\:\\];='#]\",'',x))\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZsHaMWywaFN"
      },
      "outputs": [],
      "source": [
        "train_df['text']=remove_special_characters(train_df['text'])\n",
        "test_df['text']=remove_special_characters(test_df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CWKhejl0Dwk",
        "outputId": "b7fc6477-0eec-41b4-8a47-a130d866d49e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 86207 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import text,sequence\n",
        "\n",
        "MAX_NB_WORDS = 10000\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "EMBEDDING_DIM = 100\n",
        "tokenizer = text.Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(train_df['text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l6HP6630DtA",
        "outputId": "831b14d1-e037-4dba-f6ab-1b5547c9d622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHxJ5RLd0DqI",
        "outputId": "deea661c-0462-43c8-8204-0438337b425e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (36000, 250)\n",
            "Shape of label tensor: (36000, 2)\n"
          ]
        }
      ],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "train_text = tokenizer.texts_to_sequences(train_df['text'].values)\n",
        "train_text = pad_sequences(train_text, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', train_text.shape)\n",
        "\n",
        "y = pd.get_dummies(train_df['label']).values\n",
        "print('Shape of label tensor:', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MTesytk0Dnl",
        "outputId": "3bbd8b8e-91aa-4b21-d3c0-7e7c9fca7446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32400, 250) (32400, 2)\n",
            "(3600, 250) (3600, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(train_text,y, test_size = 0.10, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdgQ2NW20Dk3",
        "outputId": "e828fcfa-2ac2-4166-c6db-d089d5238bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 250, 100)          1000000   \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 250, 100)         0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               12928     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,093,586\n",
            "Trainable params: 1,093,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout,SpatialDropout1D,GlobalMaxPooling1D, Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=train_text.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnaVaJeK0DiR",
        "outputId": "f625ea46-2e4b-413f-c293-a1960c4dc510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "456/456 [==============================] - 458s 988ms/step - loss: 0.3988 - accuracy: 0.8181 - val_loss: 0.2971 - val_accuracy: 0.8849\n",
            "Epoch 2/5\n",
            "456/456 [==============================] - 449s 986ms/step - loss: 0.2307 - accuracy: 0.9121 - val_loss: 0.2824 - val_accuracy: 0.8852\n",
            "Epoch 3/5\n",
            "456/456 [==============================] - 446s 978ms/step - loss: 0.1723 - accuracy: 0.9348 - val_loss: 0.2937 - val_accuracy: 0.8883\n",
            "Epoch 4/5\n",
            "456/456 [==============================] - 448s 980ms/step - loss: 0.1365 - accuracy: 0.9515 - val_loss: 0.3122 - val_accuracy: 0.8910\n",
            "Epoch 5/5\n",
            "456/456 [==============================] - 459s 1s/step - loss: 0.1099 - accuracy: 0.9611 - val_loss: 0.3387 - val_accuracy: 0.8935\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAqgWQKj0DfB",
        "outputId": "ddd40a07-9b1d-4560-bc71-1ed249ad311d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "The sentiment of the text is: positive\n"
          ]
        }
      ],
      "source": [
        "text = \"I really enjoyed this movie. The acting was great and the plot was engaging. Highly recommend!\"\n",
        "# preprocess the text data\n",
        "# text = preprocess_text(text)\n",
        "text_sequence = tokenizer.texts_to_sequences([text])\n",
        "padded_sequence = pad_sequences(text_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "prediction = model.predict(padded_sequence)\n",
        "predicted_class = np.argmax(prediction)\n",
        "sentiment = \"positive\" if predicted_class == 1 else \"negative\"\n",
        "print(\"The sentiment of the text is:\", sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6OI5WkY0DcA",
        "outputId": "1f055d93-b296-4158-f253-73c1c4da2a09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "The sentiment of the text is: negative\n"
          ]
        }
      ],
      "source": [
        "text = \"The product was a complete waste of money. It broke within a week.\"\n",
        "\n",
        "text_sequence = tokenizer.texts_to_sequences([text])\n",
        "padded_sequence = pad_sequences(text_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "prediction = model.predict(padded_sequence)\n",
        "predicted_class = np.argmax(prediction)\n",
        "sentiment = \"positive\" if predicted_class == 1 else \"negative\"\n",
        "print(\"The sentiment of the text is:\", sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KTZVU-U0DXI",
        "outputId": "514ed609-ac68-49d5-a2ad-0f39c846e2bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n",
            "The sentiment of the text is: negative\n"
          ]
        }
      ],
      "source": [
        "text = \"I was really disappointed with this hotel.\"\n",
        "\n",
        "text_sequence = tokenizer.texts_to_sequences([text])\n",
        "padded_sequence = pad_sequences(text_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "prediction = model.predict(padded_sequence)\n",
        "predicted_class = np.argmax(prediction)\n",
        "sentiment = \"positive\" if predicted_class == 1 else \"negative\"\n",
        "print(\"The sentiment of the text is:\", sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDDH_iHV3Ixe",
        "outputId": "0325771b-6df1-4d10-9811-448d3f8e4f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 125ms/step\n",
            "The sentiment of the text is: positive\n"
          ]
        }
      ],
      "source": [
        "text = \"The room was clean and the staff was helpful.\"\n",
        "\n",
        "text_sequence = tokenizer.texts_to_sequences([text])\n",
        "padded_sequence = pad_sequences(text_sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "prediction = model.predict(padded_sequence)\n",
        "predicted_class = np.argmax(prediction)\n",
        "sentiment = \"positive\" if predicted_class == 1 else \"negative\"\n",
        "print(\"The sentiment of the text is:\", sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L568kglb3IuO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRrMIl173IrP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
